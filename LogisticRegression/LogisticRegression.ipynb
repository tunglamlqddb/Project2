{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path):\n",
    "    with open(data_path, 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "    X = []\n",
    "    Y = []\n",
    "    for line in lines:    # one doc\n",
    "        single_dict = defaultdict(lambda:0)\n",
    "        raw_X = line.split('<fff>')[-1]\n",
    "        for pair in raw_X.split():\n",
    "            idx = pair.split(':')[0]\n",
    "            value = pair.split(':')[1]\n",
    "            single_dict[int(idx)] = float(value)\n",
    "            \n",
    "        X.append(single_dict)\n",
    "        Y.append(float(line.split('<fff>')[0]))\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = get_data(\"D:\\\\movedFromC\\\\123\\\\20192\\\\PRJ2\\\\Project2\\\\words_tfidfs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = get_data(\"D:\\\\movedFromC\\\\123\\\\20192\\\\PRJ2\\\\Project2\\\\words_tfidfs_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "def convert_to_csr(X_dict, num_of_features):\n",
    "    X_mat = sp.dok_matrix((len(X_dict), num_of_features), dtype=np.float)\n",
    "    for i in range(len(X_dict)):\n",
    "        for key in X_dict[i].keys():\n",
    "            X_mat[i, key] = X_dict[i][key]\n",
    "    X_mat = X_mat.tocsr()\n",
    "    \n",
    "    ones = np.array([[1] for _ in range(X_mat.shape[0])])\n",
    "    X_mat_added_1 = sp.hstack([ones, X_mat]).tocsr()\n",
    "    \n",
    "    return X_mat_added_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mat = convert_to_csr(X_train, 10272)\n",
    "X_test_mat = convert_to_csr(X_test, 10272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Y_mat(Y, num_of_classes):\n",
    "    Y = np.array(Y)\n",
    "    Y_mat = np.zeros((len(Y), num_of_classes))\n",
    "    for i in range(num_of_classes):\n",
    "        Y_mat[:, i] = np.where(Y == i, 1, 0)\n",
    "    \n",
    "    return Y_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_mat = create_Y_mat(Y_train, 20)\n",
    "Y_test_mat = create_Y_mat(Y_test, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J_reg(x, y, w, LAMBDA):    # for SGD\n",
    "    z = sigmoid((x*w)[0][0])\n",
    "    J = -(y * np.log(z) + (1-y) * np.log(1-z))\n",
    " #   return (J + LAMBDA * 1./2 * np.dot(w.transpose(), w))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression_self(X, Y, w_init, lr, LAMBDA, tol = 1e-4, max_iter = 10000):\n",
    "    w = [w_init]\n",
    "   # w = w_init\n",
    "    m = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "    count = 0\n",
    "    isBreak = 0\n",
    "    check_w_after = 20\n",
    "    while count < max_iter:\n",
    "        # mix data\n",
    "        arr = np.array(range(m))\n",
    "        np.random.shuffle(arr)\n",
    "        for i in arr:\n",
    "            xi = X[i, :]\n",
    "            yi = Y[i]\n",
    "            zi = sigmoid(sp.csr_matrix.dot(xi, w[-1]))\n",
    "       #     w_new = w[-1] - lr * (float(zi-yi) * xi.transpose() + LAMBDA * w[-1])\n",
    "            # no L2 reg\n",
    "            w_new = w[-1] - lr * (float(zi-yi) * xi.transpose())\n",
    "            count += 1\n",
    "            if count%check_w_after == 0:\n",
    "                if np.linalg.norm(w_new - w[-check_w_after]) < tol:\n",
    "                    return w_new, 1\n",
    "                w.clear\n",
    "            w.append(w_new)\n",
    "            \n",
    "    \n",
    "    return w[-1],0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_best_LAMBDA(X_train, Y_train, lr):\n",
    "    def cross_validation(num_folds, LAMBDA):\n",
    "        row_ids = np.array(range(X_train.shape[0]))\n",
    "        valid_ids = np.split(row_ids[: len(row_ids) - len(row_ids) % num_folds], num_folds)\n",
    "        valid_ids[-1] = np.append(valid_ids[-1], row_ids[len(row_ids) - len(row_ids) % num_folds :])\n",
    "        train_ids = [[k for f in row_ids if k not in valid_ids[i]] for i in range(num_folds)]\n",
    "        \n",
    "        aver_loss = 0\n",
    "        for i in range(num_folds):\n",
    "            valid_part = {'X': X_train[valid_ids[i]], 'Y': Y_train[valid_ids[i]]}\n",
    "            train_part = {'X': X_train[train_ids[i]], 'Y': Y_train[train_ids[i]]}\n",
    "            w = LogisticRegression_self(train_part['X'], train_part['Y'], lr, LAMBDA)\n",
    "            aver_loss += J_reg(valid_part['X'], valid_part['Y'], w, LAMBDA)\n",
    "        return aver_loss / num_folds\n",
    "    \n",
    "    def range_scan(best_LAMBDA, minimum_loss, LAMBDA_values):\n",
    "        for curr_LAMBDA in LAMBDA_values:\n",
    "            curr_loss = cross_validation(5, curr_LAMBDA)\n",
    "            if (minimum_loss > curr_loss):\n",
    "                best_LAMBDA = curr_LAMBDA\n",
    "                minimum_loss = curr_loss\n",
    "        return best_LAMBDA, minimum_loss\n",
    "    \n",
    "    best_LAMBDA, minimum_loss = range_scan(0, 1e8, range(50))\n",
    "    LAMBDA_values = [k * 1. / 1000 for k in range(max(0, best_LAMBDA-1)*1000, (best_LAMBDA+1)*1000, 1)]\n",
    "    best_LAMBDA, minimum_loss = range_scan(best_LAMBDA, minimum_loss, LAMBDA_values)\n",
    "    return best_LAMBDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "lr = 0.5\n",
    "d = X_train_mat.shape[1]\n",
    "res = []\n",
    "t_start = time.time()\n",
    "\n",
    "for i in range(20):\n",
    "    w_init = np.random.randn(d,1)\n",
    "    w, check = LogisticRegression_self(X_train_mat, Y_train_mat[:, i], w_init, lr, 1)\n",
    "    res.append(w)\n",
    "    \n",
    "t_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314.6293170452118"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_end - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-4.1381564 ],\n",
       "        [ 0.6790387 ],\n",
       "        [-0.37100309],\n",
       "        ...,\n",
       "        [ 0.82636725],\n",
       "        [ 1.17523116],\n",
       "        [-1.86885303]])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_sample, label):\n",
    "    probs = np.zeros((20, 2))\n",
    "    for i in range(20):\n",
    "        w_opt = res[i]\n",
    "      #  w_opt= model.coef_[i]\n",
    "\n",
    "        probs[i, 0] = i\n",
    "        probs[i, 1] = float(sigmoid(sp.csr_matrix.dot(test_sample, w_opt)))\n",
    "    probs = probs[probs[:, 1].argsort()[::-1]]\n",
    "    \n",
    "    #print(\"correct label is {}\\n\".format(label))\n",
    "    #for i in range(20):\n",
    "    #    print(\"{} - prob = {:.4f}\".format(int(probs[i, 0]), probs[i, 1]))\n",
    "    return int(probs[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_train_mat[200], int(Y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X_mat, Y_dict):\n",
    "    check_true = 0\n",
    "    for i in range(X_mat.shape[0]):\n",
    "        if predict(X_mat[i], Y_dict[i]) == int(Y_dict[i]):\n",
    "            check_true += 1\n",
    "    return (check_true * 100.0 / X_mat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.79494431677567\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(X_train_mat, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.08231545406267\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(X_test_mat, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.019732236862183"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "model = LogisticRegression(solver = 'lbfgs', multi_class=\"multinomial\", max_iter=10000)\n",
    "model.fit(X_train_mat, Y_train)\n",
    "time.time() - t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0126037 ,  0.06227873, -0.03081572, ..., -0.00037624,\n",
       "       -0.00093023,  0.        ])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_[19]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 372\n",
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# use the model to make predictions with the test data\n",
    "y_pred = model.predict(X_train_mat)\n",
    "# how did our model perform?\n",
    "count_misclassified = (Y_train != y_pred).sum()\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = metrics.accuracy_score(Y_train, y_pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
