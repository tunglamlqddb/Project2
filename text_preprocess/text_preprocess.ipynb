{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "import string\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"D:\\\\movedFromC\\\\123\\\\20192\\\\PRJ2\\\\20news-bydate\\\\20news-bydate-train\"\n",
    "numOfFiles = 0\n",
    "folders = [f for f in listdir(path)]\n",
    "for i in range(len(folders)):\n",
    "    files = listdir(join(path, folders[i]))\n",
    "    for j in range(len(files)):\n",
    "        numOfFiles += 1\n",
    "numOfFiles           # number of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file = listdir(join(path, folders[0]))     # store files of folders[0]((test_file))\n",
    "\n",
    "# len(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer       # split words and punctuations\n",
    "new_punctuations = (string.punctuation)\n",
    "table = str.maketrans('', '', new_punctuations)     # remove punctuations\n",
    "\n",
    "def splitWord(words):       \n",
    "   # punc = string.punctuation().replace(\"'\", \"\")\n",
    "    tk = WordPunctTokenizer() \n",
    "    new_word = tk.tokenize(words)\n",
    "    new_word = [word.translate(table) for word in new_word]            # delete those punctuations\n",
    "    return new_word            \n",
    "\n",
    "#print(splitWord(\" \\ '' 2-----abc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import digits\n",
    "def preprocess(words):      # input is an array of words (array of strings)\n",
    "\n",
    "    table1 = str.maketrans('', '', '\\t')        # remove tabs\n",
    "    words = [word.translate(table1) for word in words]    # translate func works with string    \n",
    "    \n",
    "    #there are enters at several lines, or at the end of a line when reading line by line => remove them\n",
    "    table3 = str.maketrans('', '', '\\n')\n",
    "    words = [word.translate(table3) for word in words]\n",
    "    \n",
    "    # remove punctuations except \"'\" as they appear in stopwords, and '/' as there are 2 words that can be seperated\n",
    "#     new_punctuations = (string.punctuation).replace(\"'\", \"\")\n",
    "#     new_punctuations = new_punctuations.replace(\"/\", \"\")\n",
    "#     table2 = str.maketrans('', '', new_punctuations)\n",
    "#     words = [word.translate(table2) for word in words]\n",
    "    \n",
    " #   words = [splitWord(word) for word in words]\n",
    "    res = []\n",
    "    for word in words:\n",
    "        tem = splitWord(word)\n",
    "        for i in tem:\n",
    "            res.append(i)\n",
    "    words = res\n",
    "    \n",
    "    # remove spaces (maybe after translation, --- becomes space)\n",
    "    words = [word for word in words if word]\n",
    "    \n",
    "    \n",
    "    # unqoute '' words\n",
    "#     p_words = []\n",
    "#     for word in words:\n",
    "#         if (word[0] == \"'\" and word[len(word)-1] == \"'\"): word = word[1:len(word)-1]\n",
    "#         elif (word[0] == \"'\"): word = word[1:len(word)]\n",
    "#         elif (word[len(word)-1] == \"'\"): word = word[0: len(word)-1]\n",
    "\n",
    "#         p_words.append(word)\n",
    "#     words = p_words.copy()\n",
    "    \n",
    "    # 2nd approach: split 2 words from punctuations, 's', 've', 'll'.... included in stopwords\n",
    "    \n",
    "    # split 2 words from /\n",
    "#     tem = []\n",
    "#     for word in words:\n",
    "#         if (word.find(\"/\") != -1):\n",
    "#             i = word.find(\"/\")\n",
    "#             word1 = word[0:i]\n",
    "#             word2 = word[i+1:len(word)]\n",
    "#             tem.append(word1)\n",
    "#             tem.append(word2)\n",
    "#         else: tem.append(word)\n",
    "#     words = tem.copy()\n",
    "        \n",
    "    # remove numbers\n",
    "    words = [word for word in words if not word.isdigit()]\n",
    "    \n",
    "    # remove number from word (ex: 3DDD)\n",
    "    remove_digits = str.maketrans('', '', digits) \n",
    "    words = [word.translate(remove_digits) for word in words]\n",
    "    \n",
    "    # after removing numbers, there might be single characters or 2-letter-characters, remove them\n",
    "    words = [word for word in words if len(word) > 2]\n",
    "    \n",
    "    # lowercase\n",
    "    words = [word.lower() for word in words]\n",
    "    \n",
    "    # final step: remove left blank spaces \n",
    "    words = [word for word in words if word]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(preprocess([\"'The?\\n'\", \"\\n\", \"hahaa--\", \"Dinh/Dinhh'\", \"----12\", \"-->>a..\", \"qa\", \"3dss\", \" art \"]))\n",
    "#print(preprocess([\"\\n\"]))\n",
    "#print(len(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_metadata(listOfLines):\n",
    "    for i in range(len(listOfLines)):\n",
    "        if (listOfLines[i] == '\\n'):\n",
    "            break\n",
    "    newList = listOfLines[i+1:]\n",
    "    return newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords = ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at',\n",
    "#  'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \n",
    "#  'can', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during',\n",
    "#  'each', 'few', 'for', 'from', 'further', \n",
    "#  'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\",\n",
    "#  'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\",\n",
    "#  'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself',\n",
    "#  \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself',\n",
    "#  'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours' 'ourselves', 'out', 'over', 'own',\n",
    "#  'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', \n",
    "#  'than', 'that',\"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \n",
    "#  \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', \n",
    "#  'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where',\n",
    "#  \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\",'will', 'with', \"won't\", 'would', \"wouldn't\", \n",
    "#  'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', \n",
    "#  'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'hundred', 'thousand', '1st', '2nd', '3rd',\n",
    "#  '4th', '5th', '6th', '7th', '8th', '9th', '10th']\n",
    "from nltk.corpus import stopwords \n",
    "stopwords = set(stopwords.words('english'))\n",
    "number = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'hundred', 'thousand', '1st', '2nd', '3rd',\n",
    "'4th', '5th', '6th', '7th', '8th', '9th', '10th']\n",
    "for i in number:\n",
    "    stopwords.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words):          # input is an array of words\n",
    "    new_words = [word for word in words if word not in stopwords]\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def sentence_tokenize(line):          # token a single sentence in form of a string, return an array of words\n",
    "    words = line.strip().split()      # strip() removes leading and trailing spaces, split() removes inbetween spaces, split into list of words \n",
    "    words = preprocess(words)         # after process, words are in lowercase => can check with stopwords\n",
    "    words = remove_stopwords(words)\n",
    "    words = [ps.stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(listOfLines):           # token a whole document in a form of list of lines (strings)\n",
    "    # firstly, remove metadata\n",
    "    newList = remove_metadata(listOfLines)             \n",
    "    \n",
    "    wordsOfDoc = []     # an array to store words of one document\n",
    "    for line in newList:\n",
    "        words = sentence_tokenize(line)\n",
    "        if (len(words) > 0):              # remove enter-character-line\n",
    "            wordsOfDoc.append(words)\n",
    "        \n",
    "    return wordsOfDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(list):\n",
    "    res = []\n",
    "    for i in list:\n",
    "        for j in i: \n",
    "            res.append(j)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(a):\n",
    "    res = {}\n",
    "    for i in a:\n",
    "        if (i in res):\n",
    "            res[i] += 1            # store tf\n",
    "        else:\n",
    "            res[i] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"D:\\\\movedFromC\\\\123\\\\20192\\\\PRJ2\\\\20news-bydate\\\\20news-bydate-train\"\n",
    "folders = [f for f in listdir(path)]\n",
    "\n",
    "singleBOW = []            # list of BOW of each document\n",
    "\n",
    "#numOfWords = []           \n",
    "\n",
    "for i in range(len(folders)):\n",
    "    files = listdir(join(path, folders[i]))\n",
    "    for j in range(len(files)):\n",
    "        contentFile = open(join(join(path, folders[i]), files[j]), \"r\")\n",
    "        tem = flatten(tokenize(contentFile.readlines()))    # transform a document to a vector\n",
    "        if (len(tem) > 0):\n",
    "            singleBOW.append(tem)              # array of those document-feature-vectors\n",
    " #           numOfWords.append(freq(tem))        \n",
    "            \n",
    "        \n",
    "#len(singleBOW)               # numbers of document-feature-vectors left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = {}\n",
    "for freqVec in numOfWords:\n",
    "    uniqueWords = set(uniqueWords).union(list(freqVec))\n",
    "\n",
    "\n",
    "# for i in range(len(numOfWords)):\n",
    "#     for word in uniqueWords:\n",
    "#         if (word not in numOfWords[i]):\n",
    "#             numOfWords[i][word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "wordsToRemove = []\n",
    "idfs = {}\n",
    "n = len(numOfWords)              # number of documents\n",
    "for word in uniqueWords:\n",
    "    count = 0\n",
    "    for singleDict in numOfWords:\n",
    "        if (word in singleDict):\n",
    "            count += 1                 # numbers of docs containing word\n",
    "    if (count <= 5):\n",
    "        wordsToRemove.append(word)\n",
    "        for singleDict in numOfWords:\n",
    "            singleDict.pop(word, None)\n",
    "    else:\n",
    "        idfs[word] = math.log(n / float(count))        # compute IDF\n",
    "for word in wordsToRemove:\n",
    "    uniqueWords.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\movedFromC\\123\\20192\\anaconda\\anacondaInstallation\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-22-082bcd3e6744>\", line 4, in <module>\n",
      "    singleDict[word] = [0, 0]             # make numOfWords to be tfs\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\movedFromC\\123\\20192\\anaconda\\anacondaInstallation\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\movedFromC\\123\\20192\\anaconda\\anacondaInstallation\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\movedFromC\\123\\20192\\anaconda\\anacondaInstallation\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\movedFromC\\123\\20192\\anaconda\\anacondaInstallation\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\movedFromC\\123\\20192\\anaconda\\anacondaInstallation\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\movedFromC\\123\\20192\\anaconda\\anacondaInstallation\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\movedFromC\\123\\20192\\anaconda\\anacondaInstallation\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"D:\\movedFromC\\123\\20192\\anaconda\\anacondaInstallation\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "for singleDict in numOfWords:\n",
    "    for word in uniqueWords:\n",
    "        if (word not in singleDict):\n",
    "            singleDict[word] = [0, 0]             # make numOfWords to be tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#uniqueWords = []                       # a dictionary of whole docs\n",
    "#for i in range(len(singleBOW)):\n",
    "#    uniqueWords = set(uniqueWords).union(set(singleBOW[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"D:\\\\movedFromC\\\\123\\\\20192\\\\PRJ2\\\\dict_vector.txt\", \"w\")\n",
    "for i in list(uniqueWords):\n",
    "    f.write(\"%s \" % i)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uniqueWords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1ba24ff1b176>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m\"handgun\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muniqueWords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'uniqueWords' is not defined"
     ]
    }
   ],
   "source": [
    "\"handgun\" in uniqueWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['archiv',\n",
       " 'name',\n",
       " 'atheism',\n",
       " 'resourc',\n",
       " 'alt',\n",
       " 'atheism',\n",
       " 'archiv',\n",
       " 'name',\n",
       " 'resourc',\n",
       " 'last',\n",
       " 'modifi',\n",
       " 'decemb',\n",
       " 'version',\n",
       " 'atheist',\n",
       " 'resourc',\n",
       " 'address',\n",
       " 'atheist',\n",
       " 'organ',\n",
       " 'usa',\n",
       " 'freedom',\n",
       " 'religion',\n",
       " 'foundat',\n",
       " 'darwin',\n",
       " 'fish',\n",
       " 'bumper',\n",
       " 'sticker',\n",
       " 'assort',\n",
       " 'atheist',\n",
       " 'paraphernalia',\n",
       " 'avail',\n",
       " 'freedom',\n",
       " 'religion',\n",
       " 'foundat',\n",
       " 'write',\n",
       " 'ffrf',\n",
       " 'box',\n",
       " 'madison',\n",
       " 'telephon',\n",
       " 'evolut',\n",
       " 'design',\n",
       " 'evolut',\n",
       " 'design',\n",
       " 'sell',\n",
       " 'darwin',\n",
       " 'fish',\n",
       " 'fish',\n",
       " 'symbol',\n",
       " 'like',\n",
       " 'one',\n",
       " 'christian',\n",
       " 'stick',\n",
       " 'car',\n",
       " 'feet',\n",
       " 'word',\n",
       " 'darwin',\n",
       " 'written',\n",
       " 'insid',\n",
       " 'delux',\n",
       " 'mould',\n",
       " 'plastic',\n",
       " 'fish',\n",
       " 'postpaid',\n",
       " 'write',\n",
       " 'evolut',\n",
       " 'design',\n",
       " 'laurel',\n",
       " 'canyon',\n",
       " 'north',\n",
       " 'hollywood',\n",
       " 'peopl',\n",
       " 'san',\n",
       " 'francisco',\n",
       " 'bay',\n",
       " 'area',\n",
       " 'get',\n",
       " 'darwin',\n",
       " 'fish',\n",
       " 'lynn',\n",
       " 'gold',\n",
       " 'tri',\n",
       " 'mail',\n",
       " 'figmo',\n",
       " 'netcom',\n",
       " 'com',\n",
       " 'net',\n",
       " 'peopl',\n",
       " 'lynn',\n",
       " 'directli',\n",
       " 'price',\n",
       " 'per',\n",
       " 'fish',\n",
       " 'american',\n",
       " 'atheist',\n",
       " 'press',\n",
       " 'aap',\n",
       " 'publish',\n",
       " 'variou',\n",
       " 'atheist',\n",
       " 'book',\n",
       " 'critiqu',\n",
       " 'bibl',\n",
       " 'list',\n",
       " 'biblic',\n",
       " 'contradict',\n",
       " 'book',\n",
       " 'bibl',\n",
       " 'handbook',\n",
       " 'ball',\n",
       " 'foot',\n",
       " 'american',\n",
       " 'atheist',\n",
       " 'press',\n",
       " 'isbn',\n",
       " 'edit',\n",
       " 'bibl',\n",
       " 'contradict',\n",
       " 'absurd',\n",
       " 'atroc',\n",
       " 'immor',\n",
       " 'contain',\n",
       " 'ball',\n",
       " 'foot',\n",
       " 'bibl',\n",
       " 'contradict',\n",
       " 'aap',\n",
       " 'base',\n",
       " 'king',\n",
       " 'jame',\n",
       " 'version',\n",
       " 'bibl',\n",
       " 'write',\n",
       " 'american',\n",
       " 'atheist',\n",
       " 'press',\n",
       " 'box',\n",
       " 'austin',\n",
       " 'cameron',\n",
       " 'road',\n",
       " 'austin',\n",
       " 'telephon',\n",
       " 'fax',\n",
       " 'prometheu',\n",
       " 'book',\n",
       " 'sell',\n",
       " 'book',\n",
       " 'includ',\n",
       " 'haught',\n",
       " 'holi',\n",
       " 'horror',\n",
       " 'see',\n",
       " 'write',\n",
       " 'east',\n",
       " 'amherst',\n",
       " 'street',\n",
       " 'buffalo',\n",
       " 'new',\n",
       " 'york',\n",
       " 'telephon',\n",
       " 'altern',\n",
       " 'address',\n",
       " 'may',\n",
       " 'newer',\n",
       " 'older',\n",
       " 'prometheu',\n",
       " 'book',\n",
       " 'glenn',\n",
       " 'drive',\n",
       " 'buffalo',\n",
       " 'african',\n",
       " 'american',\n",
       " 'human',\n",
       " 'organ',\n",
       " 'promot',\n",
       " 'black',\n",
       " 'secular',\n",
       " 'human',\n",
       " 'uncov',\n",
       " 'histori',\n",
       " 'black',\n",
       " 'freethought',\n",
       " 'publish',\n",
       " 'quarterli',\n",
       " 'newslett',\n",
       " 'aah',\n",
       " 'examin',\n",
       " 'write',\n",
       " 'norm',\n",
       " 'allen',\n",
       " 'african',\n",
       " 'american',\n",
       " 'human',\n",
       " 'box',\n",
       " 'buffalo',\n",
       " 'unit',\n",
       " 'kingdom',\n",
       " 'rationalist',\n",
       " 'press',\n",
       " 'associ',\n",
       " 'nation',\n",
       " 'secular',\n",
       " 'societi',\n",
       " 'islington',\n",
       " 'high',\n",
       " 'street',\n",
       " 'holloway',\n",
       " 'road',\n",
       " 'london',\n",
       " 'london',\n",
       " 'british',\n",
       " 'humanist',\n",
       " 'associ',\n",
       " 'south',\n",
       " 'place',\n",
       " 'ethic',\n",
       " 'societi',\n",
       " 'lamb',\n",
       " 'conduit',\n",
       " 'passag',\n",
       " 'conway',\n",
       " 'hall',\n",
       " 'london',\n",
       " 'wcr',\n",
       " 'red',\n",
       " 'lion',\n",
       " 'squar',\n",
       " 'london',\n",
       " 'wcr',\n",
       " 'fax',\n",
       " 'nation',\n",
       " 'secular',\n",
       " 'societi',\n",
       " 'publish',\n",
       " 'freethink',\n",
       " 'monthli',\n",
       " 'magazin',\n",
       " 'found',\n",
       " 'germani',\n",
       " 'ibka',\n",
       " 'international',\n",
       " 'bund',\n",
       " 'der',\n",
       " 'konfessionslosen',\n",
       " 'und',\n",
       " 'atheisten',\n",
       " 'postfach',\n",
       " 'berlin',\n",
       " 'germani',\n",
       " 'ibka',\n",
       " 'publish',\n",
       " 'journal',\n",
       " 'miz',\n",
       " 'materialien',\n",
       " 'und',\n",
       " 'informationen',\n",
       " 'zur',\n",
       " 'zeit',\n",
       " 'politisch',\n",
       " 'journal',\n",
       " 'der',\n",
       " 'konfessionslosesn',\n",
       " 'und',\n",
       " 'atheisten',\n",
       " 'hrsg',\n",
       " 'ibka',\n",
       " 'miz',\n",
       " 'vertrieb',\n",
       " 'postfach',\n",
       " 'berlin',\n",
       " 'germani',\n",
       " 'atheist',\n",
       " 'book',\n",
       " 'write',\n",
       " 'ibdk',\n",
       " 'international',\n",
       " 'ucherdienst',\n",
       " 'der',\n",
       " 'konfessionslosen',\n",
       " 'postfach',\n",
       " 'hannov',\n",
       " 'germani',\n",
       " 'telephon',\n",
       " 'book',\n",
       " 'fiction',\n",
       " 'thoma',\n",
       " 'disch',\n",
       " 'santa',\n",
       " 'clau',\n",
       " 'compromis',\n",
       " 'short',\n",
       " 'stori',\n",
       " 'ultim',\n",
       " 'proof',\n",
       " 'santa',\n",
       " 'exist',\n",
       " 'charact',\n",
       " 'event',\n",
       " 'fictiti',\n",
       " 'similar',\n",
       " 'live',\n",
       " 'dead',\n",
       " 'god',\n",
       " 'well',\n",
       " 'walter',\n",
       " 'miller',\n",
       " 'canticl',\n",
       " 'leibowitz',\n",
       " 'gem',\n",
       " 'post',\n",
       " 'atom',\n",
       " 'doomsday',\n",
       " 'novel',\n",
       " 'monk',\n",
       " 'spent',\n",
       " 'live',\n",
       " 'copi',\n",
       " 'blueprint',\n",
       " 'saint',\n",
       " 'leibowitz',\n",
       " 'fill',\n",
       " 'sheet',\n",
       " 'paper',\n",
       " 'ink',\n",
       " 'leav',\n",
       " 'white',\n",
       " 'line',\n",
       " 'letter',\n",
       " 'edgar',\n",
       " 'pangborn',\n",
       " 'davi',\n",
       " 'post',\n",
       " 'atom',\n",
       " 'doomsday',\n",
       " 'novel',\n",
       " 'set',\n",
       " 'cleric',\n",
       " 'state',\n",
       " 'church',\n",
       " 'exampl',\n",
       " 'forbid',\n",
       " 'anyon',\n",
       " 'produc',\n",
       " 'describ',\n",
       " 'use',\n",
       " 'substanc',\n",
       " 'contain',\n",
       " 'atom',\n",
       " 'philip',\n",
       " 'dick',\n",
       " 'philip',\n",
       " 'dick',\n",
       " 'dick',\n",
       " 'wrote',\n",
       " 'mani',\n",
       " 'philosoph',\n",
       " 'thought',\n",
       " 'provok',\n",
       " 'short',\n",
       " 'stori',\n",
       " 'novel',\n",
       " 'stori',\n",
       " 'bizarr',\n",
       " 'time',\n",
       " 'approach',\n",
       " 'wrote',\n",
       " 'mainli',\n",
       " 'wrote',\n",
       " 'peopl',\n",
       " 'truth',\n",
       " 'religion',\n",
       " 'rather',\n",
       " 'technolog',\n",
       " 'although',\n",
       " 'often',\n",
       " 'believ',\n",
       " 'met',\n",
       " 'sort',\n",
       " 'god',\n",
       " 'remain',\n",
       " 'sceptic',\n",
       " 'amongst',\n",
       " 'novel',\n",
       " 'follow',\n",
       " 'relev',\n",
       " 'galact',\n",
       " 'pot',\n",
       " 'healer',\n",
       " 'fallibl',\n",
       " 'alien',\n",
       " 'deiti',\n",
       " 'summon',\n",
       " 'group',\n",
       " 'earth',\n",
       " 'craftsmen',\n",
       " 'women',\n",
       " 'remot',\n",
       " 'planet',\n",
       " 'rais',\n",
       " 'giant',\n",
       " 'cathedr',\n",
       " 'beneath',\n",
       " 'ocean',\n",
       " 'deiti',\n",
       " 'begin',\n",
       " 'demand',\n",
       " 'faith',\n",
       " 'earther',\n",
       " 'pot',\n",
       " 'healer',\n",
       " 'joe',\n",
       " 'fernwright',\n",
       " 'unabl',\n",
       " 'compli',\n",
       " 'polish',\n",
       " 'iron',\n",
       " 'amus',\n",
       " 'novel',\n",
       " 'maze',\n",
       " 'death',\n",
       " 'noteworthi',\n",
       " 'descript',\n",
       " 'technolog',\n",
       " 'base',\n",
       " 'religion',\n",
       " 'vali',\n",
       " 'schizophren',\n",
       " 'hero',\n",
       " 'search',\n",
       " 'hidden',\n",
       " 'mysteri',\n",
       " 'gnostic',\n",
       " 'christian',\n",
       " 'realiti',\n",
       " 'fire',\n",
       " 'brain',\n",
       " 'pink',\n",
       " 'laser',\n",
       " 'beam',\n",
       " 'unknown',\n",
       " 'possibl',\n",
       " 'divin',\n",
       " 'origin',\n",
       " 'accompani',\n",
       " 'dogmat',\n",
       " 'dismiss',\n",
       " 'atheist',\n",
       " 'friend',\n",
       " 'assort',\n",
       " 'odd',\n",
       " 'charact',\n",
       " 'divin',\n",
       " 'invas',\n",
       " 'god',\n",
       " 'invad',\n",
       " 'earth',\n",
       " 'make',\n",
       " 'young',\n",
       " 'woman',\n",
       " 'pregnant',\n",
       " 'return',\n",
       " 'anoth',\n",
       " 'star',\n",
       " 'system',\n",
       " 'unfortun',\n",
       " 'termin',\n",
       " 'ill',\n",
       " 'must',\n",
       " 'assist',\n",
       " 'dead',\n",
       " 'man',\n",
       " 'whose',\n",
       " 'brain',\n",
       " 'wire',\n",
       " 'hour',\n",
       " 'easi',\n",
       " 'listen',\n",
       " 'music',\n",
       " 'margaret',\n",
       " 'atwood',\n",
       " 'handmaid',\n",
       " 'tale',\n",
       " 'stori',\n",
       " 'base',\n",
       " 'premis',\n",
       " 'congress',\n",
       " 'mysteri',\n",
       " 'assassin',\n",
       " 'fundamentalist',\n",
       " 'quickli',\n",
       " 'take',\n",
       " 'charg',\n",
       " 'nation',\n",
       " 'set',\n",
       " 'right',\n",
       " 'book',\n",
       " 'diari',\n",
       " 'woman',\n",
       " 'life',\n",
       " 'tri',\n",
       " 'live',\n",
       " 'new',\n",
       " 'christian',\n",
       " 'theocraci',\n",
       " 'women',\n",
       " 'right',\n",
       " 'properti',\n",
       " 'revok',\n",
       " 'bank',\n",
       " 'account',\n",
       " 'close',\n",
       " 'sin',\n",
       " 'luxuri',\n",
       " 'outlaw',\n",
       " 'radio',\n",
       " 'use',\n",
       " 'read',\n",
       " 'bibl',\n",
       " 'crime',\n",
       " 'punish',\n",
       " 'retroact',\n",
       " 'doctor',\n",
       " 'perform',\n",
       " 'legal',\n",
       " 'abort',\n",
       " 'old',\n",
       " 'world',\n",
       " 'hunt',\n",
       " 'hang',\n",
       " 'atwood',\n",
       " 'write',\n",
       " 'style',\n",
       " 'difficult',\n",
       " 'get',\n",
       " 'use',\n",
       " 'first',\n",
       " 'tale',\n",
       " 'grow',\n",
       " 'chill',\n",
       " 'goe',\n",
       " 'variou',\n",
       " 'author',\n",
       " 'bibl',\n",
       " 'somewhat',\n",
       " 'dull',\n",
       " 'rambl',\n",
       " 'work',\n",
       " 'often',\n",
       " 'critic',\n",
       " 'howev',\n",
       " 'probabl',\n",
       " 'worth',\n",
       " 'read',\n",
       " 'know',\n",
       " 'fuss',\n",
       " 'exist',\n",
       " 'mani',\n",
       " 'differ',\n",
       " 'version',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'get',\n",
       " 'true',\n",
       " 'version',\n",
       " 'book',\n",
       " 'non',\n",
       " 'fiction',\n",
       " 'peter',\n",
       " 'rosa',\n",
       " 'vicar',\n",
       " 'christ',\n",
       " 'bantam',\n",
       " 'press',\n",
       " 'although',\n",
       " 'rosa',\n",
       " 'seem',\n",
       " 'christian',\n",
       " 'even',\n",
       " 'cathol',\n",
       " 'enlight',\n",
       " 'histori',\n",
       " 'papal',\n",
       " 'immor',\n",
       " 'adulteri',\n",
       " 'fallaci',\n",
       " 'etc',\n",
       " 'german',\n",
       " 'translat',\n",
       " 'gott',\n",
       " 'erst',\n",
       " 'diener',\n",
       " 'die',\n",
       " 'dunkl',\n",
       " 'seit',\n",
       " 'de',\n",
       " 'papsttum',\n",
       " 'droemer',\n",
       " 'knaur',\n",
       " 'michael',\n",
       " 'martin',\n",
       " 'atheism',\n",
       " 'philosoph',\n",
       " 'justif',\n",
       " 'templ',\n",
       " 'univers',\n",
       " 'press',\n",
       " 'philadelphia',\n",
       " 'usa',\n",
       " 'detail',\n",
       " 'scholarli',\n",
       " 'justif',\n",
       " 'atheism',\n",
       " 'contain',\n",
       " 'outstand',\n",
       " 'appendix',\n",
       " 'defin',\n",
       " 'terminolog',\n",
       " 'usag',\n",
       " 'necessarili',\n",
       " 'tendenti',\n",
       " 'area',\n",
       " 'argu',\n",
       " 'neg',\n",
       " 'atheism',\n",
       " 'non',\n",
       " 'belief',\n",
       " 'exist',\n",
       " 'god',\n",
       " 'also',\n",
       " 'posit',\n",
       " 'atheism',\n",
       " 'belief',\n",
       " 'non',\n",
       " 'exist',\n",
       " 'god',\n",
       " 'includ',\n",
       " 'great',\n",
       " 'refut',\n",
       " 'challeng',\n",
       " 'argument',\n",
       " 'god',\n",
       " 'particular',\n",
       " 'attent',\n",
       " 'paid',\n",
       " 'refut',\n",
       " 'contempori',\n",
       " 'theist',\n",
       " 'platinga',\n",
       " 'swinburn',\n",
       " 'page',\n",
       " 'isbn',\n",
       " 'hardcov',\n",
       " 'paperback',\n",
       " 'also',\n",
       " 'avail',\n",
       " 'case',\n",
       " 'christian',\n",
       " 'templ',\n",
       " 'univers',\n",
       " 'press',\n",
       " 'comprehens',\n",
       " 'critiqu',\n",
       " 'christian',\n",
       " 'consid',\n",
       " 'best',\n",
       " 'contemporari',\n",
       " 'defenc',\n",
       " 'christian',\n",
       " 'ultim',\n",
       " 'demonstr',\n",
       " 'unsupport',\n",
       " 'incoher',\n",
       " 'page',\n",
       " 'isbn',\n",
       " 'jame',\n",
       " 'turner',\n",
       " 'without',\n",
       " 'god',\n",
       " 'without',\n",
       " 'creed',\n",
       " 'john',\n",
       " 'hopkin',\n",
       " 'univers',\n",
       " 'press',\n",
       " 'baltimor',\n",
       " 'usa',\n",
       " 'subtitl',\n",
       " 'origin',\n",
       " 'unbelief',\n",
       " 'america',\n",
       " 'examin',\n",
       " 'way',\n",
       " 'unbelief',\n",
       " 'whether',\n",
       " 'agnost',\n",
       " 'atheist',\n",
       " 'becam',\n",
       " 'mainstream',\n",
       " 'altern',\n",
       " 'world',\n",
       " 'view',\n",
       " 'focuss',\n",
       " 'period',\n",
       " 'consid',\n",
       " 'franc',\n",
       " 'britain',\n",
       " 'emphasi',\n",
       " 'american',\n",
       " 'particularli',\n",
       " 'new',\n",
       " 'england',\n",
       " 'develop',\n",
       " 'neither',\n",
       " 'religi',\n",
       " 'histori',\n",
       " 'secular',\n",
       " 'atheism',\n",
       " 'without',\n",
       " 'god',\n",
       " 'without',\n",
       " 'creed',\n",
       " 'rather',\n",
       " 'intellectu',\n",
       " 'histori',\n",
       " 'fate',\n",
       " 'singl',\n",
       " 'idea',\n",
       " 'belief',\n",
       " 'god',\n",
       " 'exist',\n",
       " 'page',\n",
       " 'isbn',\n",
       " 'hardcov',\n",
       " 'paper',\n",
       " 'georg',\n",
       " 'seld',\n",
       " 'editor',\n",
       " 'great',\n",
       " 'thought',\n",
       " 'ballantin',\n",
       " 'book',\n",
       " 'new',\n",
       " 'york',\n",
       " 'usa',\n",
       " 'dictionari',\n",
       " 'quotat',\n",
       " 'differ',\n",
       " 'kind',\n",
       " 'concentr',\n",
       " 'statement',\n",
       " 'write',\n",
       " 'explicitli',\n",
       " 'implicitli',\n",
       " 'present',\n",
       " 'person',\n",
       " 'philosophi',\n",
       " 'world',\n",
       " 'view',\n",
       " 'includ',\n",
       " 'obscur',\n",
       " 'often',\n",
       " 'suppress',\n",
       " 'opinion',\n",
       " 'mani',\n",
       " 'peopl',\n",
       " 'popular',\n",
       " 'observ',\n",
       " 'trace',\n",
       " 'way',\n",
       " 'variou',\n",
       " 'peopl',\n",
       " 'express',\n",
       " 'twist',\n",
       " 'idea',\n",
       " 'centuri',\n",
       " 'quit',\n",
       " 'number',\n",
       " 'quotat',\n",
       " 'deriv',\n",
       " 'cardiff',\n",
       " 'great',\n",
       " 'men',\n",
       " 'think',\n",
       " 'religion',\n",
       " 'noy',\n",
       " 'view',\n",
       " 'religion',\n",
       " 'page',\n",
       " 'isbn',\n",
       " 'paper',\n",
       " 'richard',\n",
       " 'swinburn',\n",
       " 'exist',\n",
       " 'god',\n",
       " 'revis',\n",
       " 'edit',\n",
       " 'clarendon',\n",
       " 'paperback',\n",
       " 'oxford',\n",
       " 'book',\n",
       " 'second',\n",
       " 'volum',\n",
       " 'trilog',\n",
       " 'began',\n",
       " 'coher',\n",
       " 'theism',\n",
       " 'conclud',\n",
       " 'faith',\n",
       " 'reason',\n",
       " 'work',\n",
       " 'swinburn',\n",
       " 'attempt',\n",
       " 'construct',\n",
       " 'seri',\n",
       " 'induct',\n",
       " 'argument',\n",
       " 'exist',\n",
       " 'god',\n",
       " 'argument',\n",
       " 'somewhat',\n",
       " 'tendenti',\n",
       " 'reli',\n",
       " 'upon',\n",
       " 'imput',\n",
       " 'late',\n",
       " 'centuri',\n",
       " 'western',\n",
       " 'christian',\n",
       " 'valu',\n",
       " 'aesthet',\n",
       " 'god',\n",
       " 'supposedli',\n",
       " 'simpl',\n",
       " 'conceiv',\n",
       " 'decis',\n",
       " 'reject',\n",
       " 'macki',\n",
       " 'miracl',\n",
       " 'theism',\n",
       " 'revis',\n",
       " 'edit',\n",
       " 'exist',\n",
       " 'god',\n",
       " 'swinburn',\n",
       " 'includ',\n",
       " 'appendix',\n",
       " 'make',\n",
       " 'somewhat',\n",
       " 'incoher',\n",
       " 'attempt',\n",
       " 'rebut',\n",
       " 'macki',\n",
       " 'macki',\n",
       " 'miracl',\n",
       " 'theism',\n",
       " 'oxford',\n",
       " 'posthum',\n",
       " 'volum',\n",
       " 'contain',\n",
       " 'comprehens',\n",
       " 'review',\n",
       " 'princip',\n",
       " 'argument',\n",
       " 'exist',\n",
       " 'god',\n",
       " 'rang',\n",
       " 'classic',\n",
       " 'philosoph',\n",
       " 'posit',\n",
       " 'descart',\n",
       " 'anselm',\n",
       " 'berkeley',\n",
       " 'hume',\n",
       " 'moral',\n",
       " 'argument',\n",
       " 'newman',\n",
       " 'kant',\n",
       " 'sidgwick',\n",
       " 'recent',\n",
       " 'restat',\n",
       " 'classic',\n",
       " 'these',\n",
       " 'plantinga',\n",
       " 'swinburn',\n",
       " 'also',\n",
       " 'address',\n",
       " 'posit',\n",
       " 'push',\n",
       " 'concept',\n",
       " 'god',\n",
       " 'beyond',\n",
       " 'realm',\n",
       " 'ration',\n",
       " 'kierkegaard',\n",
       " 'kung',\n",
       " 'philip',\n",
       " 'well',\n",
       " 'replac',\n",
       " 'god',\n",
       " 'leli',\n",
       " 'axiarch',\n",
       " 'book',\n",
       " 'delight',\n",
       " 'read',\n",
       " 'less',\n",
       " 'formalist',\n",
       " 'better',\n",
       " 'written',\n",
       " 'martin',\n",
       " 'work',\n",
       " 'refreshingli',\n",
       " 'direct',\n",
       " 'compar',\n",
       " 'hand',\n",
       " 'wave',\n",
       " 'swinburn',\n",
       " 'jame',\n",
       " 'haught',\n",
       " 'holi',\n",
       " 'horror',\n",
       " 'illustr',\n",
       " 'histori',\n",
       " 'religi',\n",
       " 'murder',\n",
       " 'mad',\n",
       " 'prometheu',\n",
       " 'book',\n",
       " 'look',\n",
       " 'religi',\n",
       " 'persecut',\n",
       " 'ancient',\n",
       " 'time',\n",
       " 'present',\n",
       " 'day',\n",
       " 'christian',\n",
       " 'librari',\n",
       " 'congress',\n",
       " 'catalog',\n",
       " 'card',\n",
       " 'number',\n",
       " 'norm',\n",
       " 'allen',\n",
       " 'african',\n",
       " 'american',\n",
       " 'human',\n",
       " 'antholog',\n",
       " 'see',\n",
       " 'list',\n",
       " 'african',\n",
       " 'american',\n",
       " 'human',\n",
       " 'gordon',\n",
       " 'stein',\n",
       " 'antholog',\n",
       " 'atheism',\n",
       " 'ration',\n",
       " 'prometheu',\n",
       " 'book',\n",
       " 'antholog',\n",
       " 'cover',\n",
       " 'wide',\n",
       " 'rang',\n",
       " 'subject',\n",
       " 'includ',\n",
       " 'devil',\n",
       " 'evil',\n",
       " 'moral',\n",
       " 'histori',\n",
       " 'freethought',\n",
       " 'comprehens',\n",
       " 'bibliographi',\n",
       " 'edmund',\n",
       " 'cohen',\n",
       " 'mind',\n",
       " 'bibl',\n",
       " 'believ',\n",
       " 'prometheu',\n",
       " 'book',\n",
       " 'studi',\n",
       " 'peopl',\n",
       " 'becom',\n",
       " 'christian',\n",
       " 'fundamentalist',\n",
       " 'effect',\n",
       " 'net',\n",
       " 'resourc',\n",
       " 'small',\n",
       " 'mail',\n",
       " 'base',\n",
       " 'archiv',\n",
       " 'server',\n",
       " 'manti',\n",
       " 'carri',\n",
       " 'archiv',\n",
       " 'old',\n",
       " 'alt',\n",
       " 'atheism',\n",
       " 'moder',\n",
       " 'articl',\n",
       " 'assort',\n",
       " 'file',\n",
       " 'inform',\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(singleBOW)        # No of documents\n",
    "#check = 0\n",
    "#for i in range(1064):\n",
    "#    if (len(singleBOW[i]) == 0):\n",
    "#        check = i\n",
    "#        break\n",
    "singleBOW[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numOfWords = []                  # dictionary of words and occurence for each document\n",
    "#for i in range(len(singleBOW)):\n",
    "#    tem = dict.fromkeys(uniqueWords, 0)\n",
    "#    for word in singleBOW[i]:\n",
    "#        tem[word] += 1\n",
    "#    numOfWords.append(tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def computeTF(wordDict, BOW):\n",
    "#     tfDict = {}                # tf of our dictionary\n",
    "#     volOfBOW = len(BOW)  \n",
    "#     for word, count in wordDict.items():\n",
    "#         tfDict[word] = count / float(volOfBOW)\n",
    "#     return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfs = []\n",
    "# for i in range(len(singleBOW)):\n",
    "#     tem = computeTF(numOfWords[i], singleBOW[i])\n",
    "#     tfs.append(tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# def computeIDF(docs):\n",
    "#     n = len(docs)\n",
    "#     idfDict = dict.fromkeys(uniqueWords, 0)\n",
    "#     for doc in docs:\n",
    "#         for word, count in doc.items():\n",
    "#             if count > 0:\n",
    "#                 idfDict[word] += 1     # #of docs containing word\n",
    "#     for word, count in idfDict.items():\n",
    "#         idfDict[word] = math.log(n / float(count))\n",
    "#     return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idfs = computeIDF(numOfWords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFxIDF(tf, idfs):\n",
    "    tfidf = {}\n",
    "    for word, count in tf.items():\n",
    "        tfidf[word] = count * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = []\n",
    "for i in range(len(numOfWords)):\n",
    "    tem = computeTFxIDF(numOfWords[i], idfs)\n",
    "    tfidf.append(tem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"D:\\\\movedFromC\\\\123\\\\20192\\\\PRJ2\\\\TFxIDF_vector.txt\", \"w\")\n",
    "for word, count in tfidf:\n",
    "    f.write(\"%s - %f\" %(word, count)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11295x8763 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 898896 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(min_df=11)\n",
    "\n",
    "preprocessedData = []\n",
    "for i in range(len(singleBOW)):\n",
    "    preprocessedData.append(\" \".join(singleBOW[i]))\n",
    "\n",
    "X_train_counts = tfidf_vect.fit_transform(preprocessedData)\n",
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['archiv',\n",
       " 'name',\n",
       " 'atheism',\n",
       " 'resourc',\n",
       " 'alt',\n",
       " 'atheism',\n",
       " 'archiv',\n",
       " 'name',\n",
       " 'resourc',\n",
       " 'last',\n",
       " 'modifi',\n",
       " 'decemb',\n",
       " 'version',\n",
       " 'atheist',\n",
       " 'resourc',\n",
       " 'address',\n",
       " 'atheist',\n",
       " 'organ',\n",
       " 'usa',\n",
       " 'freedom',\n",
       " 'religion',\n",
       " 'foundat',\n",
       " 'darwin',\n",
       " 'fish',\n",
       " 'bumper',\n",
       " 'sticker',\n",
       " 'assort',\n",
       " 'atheist',\n",
       " 'paraphernalia',\n",
       " 'avail',\n",
       " 'freedom',\n",
       " 'religion',\n",
       " 'foundat',\n",
       " 'write',\n",
       " 'ffrf',\n",
       " 'box',\n",
       " 'madison',\n",
       " 'telephon',\n",
       " 'evolut',\n",
       " 'design',\n",
       " 'evolut',\n",
       " 'design',\n",
       " 'sell',\n",
       " 'darwin',\n",
       " 'fish',\n",
       " 'fish',\n",
       " 'symbol',\n",
       " 'like',\n",
       " 'one',\n",
       " 'christian',\n",
       " 'stick',\n",
       " 'car',\n",
       " 'feet',\n",
       " 'word',\n",
       " 'darwin',\n",
       " 'written',\n",
       " 'insid',\n",
       " 'delux',\n",
       " 'mould',\n",
       " 'plastic',\n",
       " 'fish',\n",
       " 'postpaid',\n",
       " 'write',\n",
       " 'evolut',\n",
       " 'design',\n",
       " 'laurel',\n",
       " 'canyon',\n",
       " 'north',\n",
       " 'hollywood',\n",
       " 'peopl',\n",
       " 'san',\n",
       " 'francisco',\n",
       " 'bay',\n",
       " 'area',\n",
       " 'get',\n",
       " 'darwin',\n",
       " 'fish',\n",
       " 'lynn',\n",
       " 'gold',\n",
       " 'tri',\n",
       " 'mail',\n",
       " 'figmo',\n",
       " 'netcom',\n",
       " 'com',\n",
       " 'net',\n",
       " 'peopl',\n",
       " 'lynn',\n",
       " 'directli',\n",
       " 'price',\n",
       " 'per',\n",
       " 'fish',\n",
       " 'american',\n",
       " 'atheist',\n",
       " 'press',\n",
       " 'aap',\n",
       " 'publish',\n",
       " 'variou',\n",
       " 'atheist',\n",
       " 'book',\n",
       " 'critiqu',\n",
       " 'bibl',\n",
       " 'list',\n",
       " 'biblic',\n",
       " 'contradict',\n",
       " 'book',\n",
       " 'bibl',\n",
       " 'handbook',\n",
       " 'ball',\n",
       " 'foot',\n",
       " 'american',\n",
       " 'atheist',\n",
       " 'press',\n",
       " 'isbn',\n",
       " 'edit',\n",
       " 'bibl',\n",
       " 'contradict',\n",
       " 'absurd',\n",
       " 'atroc',\n",
       " 'immor',\n",
       " 'contain',\n",
       " 'ball',\n",
       " 'foot',\n",
       " 'bibl',\n",
       " 'contradict',\n",
       " 'aap',\n",
       " 'base',\n",
       " 'king',\n",
       " 'jame',\n",
       " 'version',\n",
       " 'bibl',\n",
       " 'write',\n",
       " 'american',\n",
       " 'atheist',\n",
       " 'press',\n",
       " 'box',\n",
       " 'austin',\n",
       " 'cameron',\n",
       " 'road',\n",
       " 'austin',\n",
       " 'telephon',\n",
       " 'fax',\n",
       " 'prometheu',\n",
       " 'book',\n",
       " 'sell',\n",
       " 'book',\n",
       " 'includ',\n",
       " 'haught',\n",
       " 'holi',\n",
       " 'horror',\n",
       " 'see',\n",
       " 'write',\n",
       " 'east',\n",
       " 'amherst',\n",
       " 'street',\n",
       " 'buffalo',\n",
       " 'new',\n",
       " 'york',\n",
       " 'telephon',\n",
       " 'altern',\n",
       " 'address',\n",
       " 'may',\n",
       " 'newer',\n",
       " 'older',\n",
       " 'prometheu',\n",
       " 'book',\n",
       " 'glenn',\n",
       " 'drive',\n",
       " 'buffalo',\n",
       " 'african',\n",
       " 'american',\n",
       " 'human',\n",
       " 'organ',\n",
       " 'promot',\n",
       " 'black',\n",
       " 'secular',\n",
       " 'human',\n",
       " 'uncov',\n",
       " 'histori',\n",
       " 'black',\n",
       " 'freethought',\n",
       " 'publish',\n",
       " 'quarterli',\n",
       " 'newslett',\n",
       " 'aah',\n",
       " 'examin',\n",
       " 'write',\n",
       " 'norm',\n",
       " 'allen',\n",
       " 'african',\n",
       " 'american',\n",
       " 'human',\n",
       " 'box',\n",
       " 'buffalo',\n",
       " 'unit',\n",
       " 'kingdom',\n",
       " 'rationalist',\n",
       " 'press',\n",
       " 'associ',\n",
       " 'nation',\n",
       " 'secular',\n",
       " 'societi',\n",
       " 'islington',\n",
       " 'high',\n",
       " 'street',\n",
       " 'holloway',\n",
       " 'road',\n",
       " 'london',\n",
       " 'london',\n",
       " 'british',\n",
       " 'humanist',\n",
       " 'associ',\n",
       " 'south',\n",
       " 'place',\n",
       " 'ethic',\n",
       " 'societi',\n",
       " 'lamb',\n",
       " 'conduit',\n",
       " 'passag',\n",
       " 'conway',\n",
       " 'hall',\n",
       " 'london',\n",
       " 'wcr',\n",
       " 'red',\n",
       " 'lion',\n",
       " 'squar',\n",
       " 'london',\n",
       " 'wcr',\n",
       " 'fax',\n",
       " 'nation',\n",
       " 'secular',\n",
       " 'societi',\n",
       " 'publish',\n",
       " 'freethink',\n",
       " 'monthli',\n",
       " 'magazin',\n",
       " 'found',\n",
       " 'germani',\n",
       " 'ibka',\n",
       " 'international',\n",
       " 'bund',\n",
       " 'der',\n",
       " 'konfessionslosen',\n",
       " 'und',\n",
       " 'atheisten',\n",
       " 'postfach',\n",
       " 'berlin',\n",
       " 'germani',\n",
       " 'ibka',\n",
       " 'publish',\n",
       " 'journal',\n",
       " 'miz',\n",
       " 'materialien',\n",
       " 'und',\n",
       " 'informationen',\n",
       " 'zur',\n",
       " 'zeit',\n",
       " 'politisch',\n",
       " 'journal',\n",
       " 'der',\n",
       " 'konfessionslosesn',\n",
       " 'und',\n",
       " 'atheisten',\n",
       " 'hrsg',\n",
       " 'ibka',\n",
       " 'miz',\n",
       " 'vertrieb',\n",
       " 'postfach',\n",
       " 'berlin',\n",
       " 'germani',\n",
       " 'atheist',\n",
       " 'book',\n",
       " 'write',\n",
       " 'ibdk',\n",
       " 'international',\n",
       " 'ucherdienst',\n",
       " 'der',\n",
       " 'konfessionslosen',\n",
       " 'postfach',\n",
       " 'hannov',\n",
       " 'germani',\n",
       " 'telephon',\n",
       " 'book',\n",
       " 'fiction',\n",
       " 'thoma',\n",
       " 'disch',\n",
       " 'santa',\n",
       " 'clau',\n",
       " 'compromis',\n",
       " 'short',\n",
       " 'stori',\n",
       " 'ultim',\n",
       " 'proof',\n",
       " 'santa',\n",
       " 'exist',\n",
       " 'charact',\n",
       " 'event',\n",
       " 'fictiti',\n",
       " 'similar',\n",
       " 'live',\n",
       " 'dead',\n",
       " 'god',\n",
       " 'well',\n",
       " 'walter',\n",
       " 'miller',\n",
       " 'canticl',\n",
       " 'leibowitz',\n",
       " 'gem',\n",
       " 'post',\n",
       " 'atom',\n",
       " 'doomsday',\n",
       " 'novel',\n",
       " 'monk',\n",
       " 'spent',\n",
       " 'live',\n",
       " 'copi',\n",
       " 'blueprint',\n",
       " 'saint',\n",
       " 'leibowitz',\n",
       " 'fill',\n",
       " 'sheet',\n",
       " 'paper',\n",
       " 'ink',\n",
       " 'leav',\n",
       " 'white',\n",
       " 'line',\n",
       " 'letter',\n",
       " 'edgar',\n",
       " 'pangborn',\n",
       " 'davi',\n",
       " 'post',\n",
       " 'atom',\n",
       " 'doomsday',\n",
       " 'novel',\n",
       " 'set',\n",
       " 'cleric',\n",
       " 'state',\n",
       " 'church',\n",
       " 'exampl',\n",
       " 'forbid',\n",
       " 'anyon',\n",
       " 'produc',\n",
       " 'describ',\n",
       " 'use',\n",
       " 'substanc',\n",
       " 'contain',\n",
       " 'atom',\n",
       " 'philip',\n",
       " 'dick',\n",
       " 'philip',\n",
       " 'dick',\n",
       " 'dick',\n",
       " 'wrote',\n",
       " 'mani',\n",
       " 'philosoph',\n",
       " 'thought',\n",
       " 'provok',\n",
       " 'short',\n",
       " 'stori',\n",
       " 'novel',\n",
       " 'stori',\n",
       " 'bizarr',\n",
       " 'time',\n",
       " 'approach',\n",
       " 'wrote',\n",
       " 'mainli',\n",
       " 'wrote',\n",
       " 'peopl',\n",
       " 'truth',\n",
       " 'religion',\n",
       " 'rather',\n",
       " 'technolog',\n",
       " 'although',\n",
       " 'often',\n",
       " 'believ',\n",
       " 'met',\n",
       " 'sort',\n",
       " 'god',\n",
       " 'remain',\n",
       " 'sceptic',\n",
       " 'amongst',\n",
       " 'novel',\n",
       " 'follow',\n",
       " 'relev',\n",
       " 'galact',\n",
       " 'pot',\n",
       " 'healer',\n",
       " 'fallibl',\n",
       " 'alien',\n",
       " 'deiti',\n",
       " 'summon',\n",
       " 'group',\n",
       " 'earth',\n",
       " 'craftsmen',\n",
       " 'women',\n",
       " 'remot',\n",
       " 'planet',\n",
       " 'rais',\n",
       " 'giant',\n",
       " 'cathedr',\n",
       " 'beneath',\n",
       " 'ocean',\n",
       " 'deiti',\n",
       " 'begin',\n",
       " 'demand',\n",
       " 'faith',\n",
       " 'earther',\n",
       " 'pot',\n",
       " 'healer',\n",
       " 'joe',\n",
       " 'fernwright',\n",
       " 'unabl',\n",
       " 'compli',\n",
       " 'polish',\n",
       " 'iron',\n",
       " 'amus',\n",
       " 'novel',\n",
       " 'maze',\n",
       " 'death',\n",
       " 'noteworthi',\n",
       " 'descript',\n",
       " 'technolog',\n",
       " 'base',\n",
       " 'religion',\n",
       " 'vali',\n",
       " 'schizophren',\n",
       " 'hero',\n",
       " 'search',\n",
       " 'hidden',\n",
       " 'mysteri',\n",
       " 'gnostic',\n",
       " 'christian',\n",
       " 'realiti',\n",
       " 'fire',\n",
       " 'brain',\n",
       " 'pink',\n",
       " 'laser',\n",
       " 'beam',\n",
       " 'unknown',\n",
       " 'possibl',\n",
       " 'divin',\n",
       " 'origin',\n",
       " 'accompani',\n",
       " 'dogmat',\n",
       " 'dismiss',\n",
       " 'atheist',\n",
       " 'friend',\n",
       " 'assort',\n",
       " 'odd',\n",
       " 'charact',\n",
       " 'divin',\n",
       " 'invas',\n",
       " 'god',\n",
       " 'invad',\n",
       " 'earth',\n",
       " 'make',\n",
       " 'young',\n",
       " 'woman',\n",
       " 'pregnant',\n",
       " 'return',\n",
       " 'anoth',\n",
       " 'star',\n",
       " 'system',\n",
       " 'unfortun',\n",
       " 'termin',\n",
       " 'ill',\n",
       " 'must',\n",
       " 'assist',\n",
       " 'dead',\n",
       " 'man',\n",
       " 'whose',\n",
       " 'brain',\n",
       " 'wire',\n",
       " 'hour',\n",
       " 'easi',\n",
       " 'listen',\n",
       " 'music',\n",
       " 'margaret',\n",
       " 'atwood',\n",
       " 'handmaid',\n",
       " 'tale',\n",
       " 'stori',\n",
       " 'base',\n",
       " 'premis',\n",
       " 'congress',\n",
       " 'mysteri',\n",
       " 'assassin',\n",
       " 'fundamentalist',\n",
       " 'quickli',\n",
       " 'take',\n",
       " 'charg',\n",
       " 'nation',\n",
       " 'set',\n",
       " 'right',\n",
       " 'book',\n",
       " 'diari',\n",
       " 'woman',\n",
       " 'life',\n",
       " 'tri',\n",
       " 'live',\n",
       " 'new',\n",
       " 'christian',\n",
       " 'theocraci',\n",
       " 'women',\n",
       " 'right',\n",
       " 'properti',\n",
       " 'revok',\n",
       " 'bank',\n",
       " 'account',\n",
       " 'close',\n",
       " 'sin',\n",
       " 'luxuri',\n",
       " 'outlaw',\n",
       " 'radio',\n",
       " 'use',\n",
       " 'read',\n",
       " 'bibl',\n",
       " 'crime',\n",
       " 'punish',\n",
       " 'retroact',\n",
       " 'doctor',\n",
       " 'perform',\n",
       " 'legal',\n",
       " 'abort',\n",
       " 'old',\n",
       " 'world',\n",
       " 'hunt',\n",
       " 'hang',\n",
       " 'atwood',\n",
       " 'write',\n",
       " 'style',\n",
       " 'difficult',\n",
       " 'get',\n",
       " 'use',\n",
       " 'first',\n",
       " 'tale',\n",
       " 'grow',\n",
       " 'chill',\n",
       " 'goe',\n",
       " 'variou',\n",
       " 'author',\n",
       " 'bibl',\n",
       " 'somewhat',\n",
       " 'dull',\n",
       " 'rambl',\n",
       " 'work',\n",
       " 'often',\n",
       " 'critic',\n",
       " 'howev',\n",
       " 'probabl',\n",
       " 'worth',\n",
       " 'read',\n",
       " 'know',\n",
       " 'fuss',\n",
       " 'exist',\n",
       " 'mani',\n",
       " 'differ',\n",
       " 'version',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'get',\n",
       " 'true',\n",
       " 'version',\n",
       " 'book',\n",
       " 'non',\n",
       " 'fiction',\n",
       " 'peter',\n",
       " 'rosa',\n",
       " 'vicar',\n",
       " 'christ',\n",
       " 'bantam',\n",
       " 'press',\n",
       " 'although',\n",
       " 'rosa',\n",
       " 'seem',\n",
       " 'christian',\n",
       " 'even',\n",
       " 'cathol',\n",
       " 'enlight',\n",
       " 'histori',\n",
       " 'papal',\n",
       " 'immor',\n",
       " 'adulteri',\n",
       " 'fallaci',\n",
       " 'etc',\n",
       " 'german',\n",
       " 'translat',\n",
       " 'gott',\n",
       " 'erst',\n",
       " 'diener',\n",
       " 'die',\n",
       " 'dunkl',\n",
       " 'seit',\n",
       " 'de',\n",
       " 'papsttum',\n",
       " 'droemer',\n",
       " 'knaur',\n",
       " 'michael',\n",
       " 'martin',\n",
       " 'atheism',\n",
       " 'philosoph',\n",
       " 'justif',\n",
       " 'templ',\n",
       " 'univers',\n",
       " 'press',\n",
       " 'philadelphia',\n",
       " 'usa',\n",
       " 'detail',\n",
       " 'scholarli',\n",
       " 'justif',\n",
       " 'atheism',\n",
       " 'contain',\n",
       " 'outstand',\n",
       " 'appendix',\n",
       " 'defin',\n",
       " 'terminolog',\n",
       " 'usag',\n",
       " 'necessarili',\n",
       " 'tendenti',\n",
       " 'area',\n",
       " 'argu',\n",
       " 'neg',\n",
       " 'atheism',\n",
       " 'non',\n",
       " 'belief',\n",
       " 'exist',\n",
       " 'god',\n",
       " 'also',\n",
       " 'posit',\n",
       " 'atheism',\n",
       " 'belief',\n",
       " 'non',\n",
       " 'exist',\n",
       " 'god',\n",
       " 'includ',\n",
       " 'great',\n",
       " 'refut',\n",
       " 'challeng',\n",
       " 'argument',\n",
       " 'god',\n",
       " 'particular',\n",
       " 'attent',\n",
       " 'paid',\n",
       " 'refut',\n",
       " 'contempori',\n",
       " 'theist',\n",
       " 'platinga',\n",
       " 'swinburn',\n",
       " 'page',\n",
       " 'isbn',\n",
       " 'hardcov',\n",
       " 'paperback',\n",
       " 'also',\n",
       " 'avail',\n",
       " 'case',\n",
       " 'christian',\n",
       " 'templ',\n",
       " 'univers',\n",
       " 'press',\n",
       " 'comprehens',\n",
       " 'critiqu',\n",
       " 'christian',\n",
       " 'consid',\n",
       " 'best',\n",
       " 'contemporari',\n",
       " 'defenc',\n",
       " 'christian',\n",
       " 'ultim',\n",
       " 'demonstr',\n",
       " 'unsupport',\n",
       " 'incoher',\n",
       " 'page',\n",
       " 'isbn',\n",
       " 'jame',\n",
       " 'turner',\n",
       " 'without',\n",
       " 'god',\n",
       " 'without',\n",
       " 'creed',\n",
       " 'john',\n",
       " 'hopkin',\n",
       " 'univers',\n",
       " 'press',\n",
       " 'baltimor',\n",
       " 'usa',\n",
       " 'subtitl',\n",
       " 'origin',\n",
       " 'unbelief',\n",
       " 'america',\n",
       " 'examin',\n",
       " 'way',\n",
       " 'unbelief',\n",
       " 'whether',\n",
       " 'agnost',\n",
       " 'atheist',\n",
       " 'becam',\n",
       " 'mainstream',\n",
       " 'altern',\n",
       " 'world',\n",
       " 'view',\n",
       " 'focuss',\n",
       " 'period',\n",
       " 'consid',\n",
       " 'franc',\n",
       " 'britain',\n",
       " 'emphasi',\n",
       " 'american',\n",
       " 'particularli',\n",
       " 'new',\n",
       " 'england',\n",
       " 'develop',\n",
       " 'neither',\n",
       " 'religi',\n",
       " 'histori',\n",
       " 'secular',\n",
       " 'atheism',\n",
       " 'without',\n",
       " 'god',\n",
       " 'without',\n",
       " 'creed',\n",
       " 'rather',\n",
       " 'intellectu',\n",
       " 'histori',\n",
       " 'fate',\n",
       " 'singl',\n",
       " 'idea',\n",
       " 'belief',\n",
       " 'god',\n",
       " 'exist',\n",
       " 'page',\n",
       " 'isbn',\n",
       " 'hardcov',\n",
       " 'paper',\n",
       " 'georg',\n",
       " 'seld',\n",
       " 'editor',\n",
       " 'great',\n",
       " 'thought',\n",
       " 'ballantin',\n",
       " 'book',\n",
       " 'new',\n",
       " 'york',\n",
       " 'usa',\n",
       " 'dictionari',\n",
       " 'quotat',\n",
       " 'differ',\n",
       " 'kind',\n",
       " 'concentr',\n",
       " 'statement',\n",
       " 'write',\n",
       " 'explicitli',\n",
       " 'implicitli',\n",
       " 'present',\n",
       " 'person',\n",
       " 'philosophi',\n",
       " 'world',\n",
       " 'view',\n",
       " 'includ',\n",
       " 'obscur',\n",
       " 'often',\n",
       " 'suppress',\n",
       " 'opinion',\n",
       " 'mani',\n",
       " 'peopl',\n",
       " 'popular',\n",
       " 'observ',\n",
       " 'trace',\n",
       " 'way',\n",
       " 'variou',\n",
       " 'peopl',\n",
       " 'express',\n",
       " 'twist',\n",
       " 'idea',\n",
       " 'centuri',\n",
       " 'quit',\n",
       " 'number',\n",
       " 'quotat',\n",
       " 'deriv',\n",
       " 'cardiff',\n",
       " 'great',\n",
       " 'men',\n",
       " 'think',\n",
       " 'religion',\n",
       " 'noy',\n",
       " 'view',\n",
       " 'religion',\n",
       " 'page',\n",
       " 'isbn',\n",
       " 'paper',\n",
       " 'richard',\n",
       " 'swinburn',\n",
       " 'exist',\n",
       " 'god',\n",
       " 'revis',\n",
       " 'edit',\n",
       " 'clarendon',\n",
       " 'paperback',\n",
       " 'oxford',\n",
       " 'book',\n",
       " 'second',\n",
       " 'volum',\n",
       " 'trilog',\n",
       " 'began',\n",
       " 'coher',\n",
       " 'theism',\n",
       " 'conclud',\n",
       " 'faith',\n",
       " 'reason',\n",
       " 'work',\n",
       " 'swinburn',\n",
       " 'attempt',\n",
       " 'construct',\n",
       " 'seri',\n",
       " 'induct',\n",
       " 'argument',\n",
       " 'exist',\n",
       " 'god',\n",
       " 'argument',\n",
       " 'somewhat',\n",
       " 'tendenti',\n",
       " 'reli',\n",
       " 'upon',\n",
       " 'imput',\n",
       " 'late',\n",
       " 'centuri',\n",
       " 'western',\n",
       " 'christian',\n",
       " 'valu',\n",
       " 'aesthet',\n",
       " 'god',\n",
       " 'supposedli',\n",
       " 'simpl',\n",
       " 'conceiv',\n",
       " 'decis',\n",
       " 'reject',\n",
       " 'macki',\n",
       " 'miracl',\n",
       " 'theism',\n",
       " 'revis',\n",
       " 'edit',\n",
       " 'exist',\n",
       " 'god',\n",
       " 'swinburn',\n",
       " 'includ',\n",
       " 'appendix',\n",
       " 'make',\n",
       " 'somewhat',\n",
       " 'incoher',\n",
       " 'attempt',\n",
       " 'rebut',\n",
       " 'macki',\n",
       " 'macki',\n",
       " 'miracl',\n",
       " 'theism',\n",
       " 'oxford',\n",
       " 'posthum',\n",
       " 'volum',\n",
       " 'contain',\n",
       " 'comprehens',\n",
       " 'review',\n",
       " 'princip',\n",
       " 'argument',\n",
       " 'exist',\n",
       " 'god',\n",
       " 'rang',\n",
       " 'classic',\n",
       " 'philosoph',\n",
       " 'posit',\n",
       " 'descart',\n",
       " 'anselm',\n",
       " 'berkeley',\n",
       " 'hume',\n",
       " 'moral',\n",
       " 'argument',\n",
       " 'newman',\n",
       " 'kant',\n",
       " 'sidgwick',\n",
       " 'recent',\n",
       " 'restat',\n",
       " 'classic',\n",
       " 'these',\n",
       " 'plantinga',\n",
       " 'swinburn',\n",
       " 'also',\n",
       " 'address',\n",
       " 'posit',\n",
       " 'push',\n",
       " 'concept',\n",
       " 'god',\n",
       " 'beyond',\n",
       " 'realm',\n",
       " 'ration',\n",
       " 'kierkegaard',\n",
       " 'kung',\n",
       " 'philip',\n",
       " 'well',\n",
       " 'replac',\n",
       " 'god',\n",
       " 'leli',\n",
       " 'axiarch',\n",
       " 'book',\n",
       " 'delight',\n",
       " 'read',\n",
       " 'less',\n",
       " 'formalist',\n",
       " 'better',\n",
       " 'written',\n",
       " 'martin',\n",
       " 'work',\n",
       " 'refreshingli',\n",
       " 'direct',\n",
       " 'compar',\n",
       " 'hand',\n",
       " 'wave',\n",
       " 'swinburn',\n",
       " 'jame',\n",
       " 'haught',\n",
       " 'holi',\n",
       " 'horror',\n",
       " 'illustr',\n",
       " 'histori',\n",
       " 'religi',\n",
       " 'murder',\n",
       " 'mad',\n",
       " 'prometheu',\n",
       " 'book',\n",
       " 'look',\n",
       " 'religi',\n",
       " 'persecut',\n",
       " 'ancient',\n",
       " 'time',\n",
       " 'present',\n",
       " 'day',\n",
       " 'christian',\n",
       " 'librari',\n",
       " 'congress',\n",
       " 'catalog',\n",
       " 'card',\n",
       " 'number',\n",
       " 'norm',\n",
       " 'allen',\n",
       " 'african',\n",
       " 'american',\n",
       " 'human',\n",
       " 'antholog',\n",
       " 'see',\n",
       " 'list',\n",
       " 'african',\n",
       " 'american',\n",
       " 'human',\n",
       " 'gordon',\n",
       " 'stein',\n",
       " 'antholog',\n",
       " 'atheism',\n",
       " 'ration',\n",
       " 'prometheu',\n",
       " 'book',\n",
       " 'antholog',\n",
       " 'cover',\n",
       " 'wide',\n",
       " 'rang',\n",
       " 'subject',\n",
       " 'includ',\n",
       " 'devil',\n",
       " 'evil',\n",
       " 'moral',\n",
       " 'histori',\n",
       " 'freethought',\n",
       " 'comprehens',\n",
       " 'bibliographi',\n",
       " 'edmund',\n",
       " 'cohen',\n",
       " 'mind',\n",
       " 'bibl',\n",
       " 'believ',\n",
       " 'prometheu',\n",
       " 'book',\n",
       " 'studi',\n",
       " 'peopl',\n",
       " 'becom',\n",
       " 'christian',\n",
       " 'fundamentalist',\n",
       " 'effect',\n",
       " 'net',\n",
       " 'resourc',\n",
       " 'small',\n",
       " 'mail',\n",
       " 'base',\n",
       " 'archiv',\n",
       " 'server',\n",
       " 'manti',\n",
       " 'carri',\n",
       " 'archiv',\n",
       " 'old',\n",
       " 'alt',\n",
       " 'atheism',\n",
       " 'moder',\n",
       " 'articl',\n",
       " 'assort',\n",
       " 'file',\n",
       " 'inform',\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singleBOW[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
